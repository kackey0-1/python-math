{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf614c9e-4ca9-4e38-959e-f8fd113388ae",
   "metadata": {},
   "source": [
    "# 人工知能とは\n",
    "- 人間のように考えるアルゴリズム\n",
    "- 車の自動運転\n",
    "\n",
    "人工知能(機械学習(深層学習))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece215d4-3243-4d6a-89cf-a21d31c63962",
   "metadata": {},
   "source": [
    "## 機械学習\n",
    "- 世の中の特定の事象についてデータを解析して、判断や予測を行うためのアルゴリズム\n",
    "- データから反復的に学習し、そこに潜むパターンを探し出すこと\n",
    "  - 机のパターン\n",
    "    - 四角\n",
    "    - 茶色\n",
    "  - りんごのパターン\n",
    "    - 丸\n",
    "    - 赤\n",
    "\n",
    "しかし、人間には簡単でも、コンピュータにとっては、りんごと椅子の画像からパターンを見つけ出すことはとても難しい。</br>\n",
    "「りんごは赤色で半径5cm程の球体」というパターンが分かっていたとしても、5cmの赤いボールをりんごと誤認してしまう。</br>\n",
    "文字(記号)と実物を対応させることができないという問題は、 \"記号接地問題\" と呼ばれ、人工知能が解決すべき難題のひとつだった。</br>\n",
    "コンピュータがりんごを認識するためには、大量のりんごの写真から共通するパターンを取得する必要がある。</br>\n",
    "これを実現するための機械学習の主な手法は下記の3つ。</br>\n",
    "\n",
    "- 教師あり学習(Supervised Learning)\n",
    "- 教師なし学習(Unsupervised Learning)\n",
    "- 強化学習(Reinforcement Learning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9d995f-22f0-48d8-90d5-27459f2f45d7",
   "metadata": {},
   "source": [
    "### 教師あり学習\n",
    "正解ラベルのついたデータを学習して、正解を予測するモデルを作る手法\n",
    "- 分類\n",
    "- 回帰\n",
    "\n",
    "の2分野ある\n",
    "\n",
    "#### 教師あり学習(分類)\n",
    "データからカテゴリを予測する問題を分類問題</br>\n",
    "例: 正解ラベルから数値、馬などを学習して予測\n",
    "\n",
    "#### 教師あり学習(回帰)\n",
    "データから数値を予測する問題を回帰と呼ぶ</br>\n",
    "例: 広さ、駅までの距離、バス・トイレ別、オートロックなどから家賃を予測"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5225c937-1ea9-4de4-8239-bea8ddf8934d",
   "metadata": {},
   "source": [
    "### 教師なし学習\n",
    "正解ラベルのついていないデータを学習して、規則性などを発見する手法\n",
    "\n",
    "- クラスタリング\n",
    "- 主成分分析\n",
    "- アソシエーション分析\n",
    "\n",
    "#### クラスタリング\n",
    "クラスタリングではデータのグループ化が可能\n",
    "#### 主成分分析\n",
    "種類の多いデータを要約（次元削減）するために使用される手法\n",
    "#### アソシエーション分析\n",
    "「1つのパターンに当てはまるデータは、もう1つのパターンにも当てはまる」といったデータのルールを見つけ出す手法</br>\n",
    "例：ネットショップなどで見かける「この商品を見た人は、こちらの商品を購入しています」といったレコメンデーションなど\n",
    "\n",
    "教師なし学習はデータの規則性を導き出したり、グループ分けしたりする場合に使用される\n",
    "実際の分析では複数の手法を組み合わせて使用されることが多い"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae43e7e0-6a3a-435f-b25f-47bd78a36bc6",
   "metadata": {},
   "source": [
    "### 強化学習\n",
    "試行錯誤を通じて、価値を最大化するようなとるべき行動を決定する手法</br>\n",
    "強化学習は利益を最大化するための方法で、 正解ラベルも大量のデータも必要としない自律的な機械学習</br>\n",
    "例: AlphaGo Zero, 歩行ロボットの制御プログラム, ゲームなどの対戦プログラム\n",
    "\n",
    "強化学習ではエージェント（行動主体）が与えられた環境を取得・観測し、行動を起こす。</br>\n",
    "行動による環境の変化によって得られる報酬（結果）の価値を最大化する。</br>\n",
    "エージェントがより価値の高い報酬を得るために、試行錯誤しながら意思決定を繰り返して自律的に学習。</br>\n",
    "[強化学習のモデルサンプル](https://www.youtube.com/watch?v=a3AWpeOjkzw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16aed1e5-6086-4210-9eef-65517627b4d0",
   "metadata": {},
   "source": [
    "## 深層学習(ディープラーニング)\n",
    "- 精度が大きく向上するブレイクスルーを巻き起こした(画像認識アルゴリズムのエラー率)\n",
    "- 生物の神経細胞の仕組みを模した\"アルゴリズム\"ニューラルネットワークの利用が主流\n",
    "- 特徴の抽出を自動で行うため、複雑なプログラミングをせずに高い精度を実現"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac892199-57a5-4764-8761-9b2de97a0850",
   "metadata": {},
   "source": [
    "# 機械学習を行うフロー\n",
    "\n",
    "1. データの収集\n",
    "2. データの前処理\n",
    "3. 機械学習のモデリング\n",
    "4. モデルのテスト\n",
    "5. モデルを公開\n",
    "\n",
    "## 「手ハガキ数字画像を自動で認識して、郵便ハガキを自動仕分けする」という教師あり学習(分類)を考える\n",
    "- 1. 手書きの数字画像を約7,000枚x10カテゴリ用意\n",
    "- 2. データの前処理\n",
    "  - 2.1 画像のサイズを統一化\n",
    "  - 2.2 全ての画像をモノクロに処理\n",
    "  - 2.3 画像のノイズを取り除く\n",
    "  - 2.4 ...etc\n",
    "- 3. データの一部(80%)を使って機械学習モデリング\n",
    "- 4. 学習に使わなかったデータ(20%)にてモデルの正解率テスト\n",
    "- 5. 郵便番号ごとに自動仕分け(推論処理)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1ae96c-3d40-4bd9-b36c-67824d2a9d05",
   "metadata": {},
   "source": [
    "## データはどれぐらい必要なのか?\n",
    "### ディープラーニング以外の場合\n",
    "scikit-learnというライブラリを利用することが多い</br>\n",
    "sampleが50個以上あるかどうかということをまず考えたりする</br>\n",
    "\n",
    "![image](./images/ml_map.png)\n",
    "[URL](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)\n",
    "\n",
    "### ディープラーニングの場合\n",
    "分類問題の場合、目安は1カテゴリ1,000枚以上\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcd14ac-a497-40f3-b43f-07ba7d01fdf0",
   "metadata": {},
   "source": [
    "## データがない場合\n",
    "\n",
    "- データを作る\n",
    "  - SNSなどから取得\n",
    "  - スクレイピングの利用\n",
    "- 転移学習を利用\n",
    "  - 学習済みモデル + 新しいデータ => 新しい学習済みモデル\n",
    "  - 例: imagenetを学習したVGG16モデル + 犬の画像データ50 & 猫の画像データ50 => 犬猫判別モデル\n",
    "- APIを利用\n",
    "  - 学習済みモデル(画像など、推論結果)\n",
    "  - 例: Google, AWS, Azure\n",
    "  - インターネット通信が必要\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccba980-22ca-49eb-9520-7b8d32922265",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## データの分割\n",
    "### 機械学習と統計学の違い\n",
    "- 機械学習\n",
    "  - モデルを構築し、未知のデータを予測・分類することを重視\n",
    "  - 例: 教師あり学習(回帰)\n",
    "- 統計学\n",
    "  - データを解析し、そのデータに至った経緯を説明することを重視\n",
    "  - 例: 重回帰分析\n",
    "\n",
    "### データの分割方法\n",
    "- 学習用データ\n",
    "  - train data\n",
    "  - 80%\n",
    "- 検証用データ\n",
    "  - test data\n",
    "  - 20%\n",
    "  \n",
    "機械学習では多くの場合、全データの20％ほどを検証データに使用</br> \n",
    "例えば、MNIST(エムニスト)という手書き文字認識の学習用データセットでは、</br>\n",
    "7万枚の画像のうち、 6万枚が訓練データ、1万枚が検証データ と分けられる。\n",
    "\n",
    "### データ分割の注意点\n",
    "テストデータを使って精度の高いモデルを恣意的に選び出すのはNG</br>\n",
    "テストデータを使った後に、モデルのチューニングを行ってはいけない\n",
    "\n",
    "- 学習用データ\n",
    "- バリデーション用データ\n",
    "- 検証用データ\n",
    "\n",
    "正解率をもとにモデルのチューニングを行う場合、バリデーションデータを使って検証を行う"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9b30f2-df42-4798-87be-31011f78fd45",
   "metadata": {},
   "source": [
    "## ホールドアウト法の理論と実践\n",
    "与えられたデータセットを訓練データと検証データの2つに分けて使用するというシンプルな手法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29b586b1-cfdc-441e-9b0a-8721143539c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train : (120, 4)\n",
      "y_train : (120,)\n",
      "X_test : (30, 4)\n",
      "y_test : (30,)\n"
     ]
    }
   ],
   "source": [
    "# コードの実行に必要なモジュールを読み込みます。\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 「IRIS」というデータセットを読み込みます。\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# 「X_train, X_test, y_train, y_test」にデータを格納します。\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# 訓練データと検証データのサイズを確認します。\n",
    "print (\"X_train :\", X_train.shape)\n",
    "print (\"y_train :\", y_train.shape)\n",
    "print (\"X_test :\", X_test.shape)\n",
    "print (\"y_test :\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4dcb33-3ab9-411d-811d-157759ce6294",
   "metadata": {
    "tags": []
   },
   "source": [
    "## k-分割交差検証の理論\n",
    "用意した訓練データセットをk分割し、 そのうちの1つを検証データ、残りのk-1個を訓練データとして使用</br>\n",
    "学習と評価を繰り返して得られるk個のモデルと性能評価から平均性能を算出<br>\n",
    "\n",
    "k-分割交差検証には、 一個抜き交差検証（Leave-One-Out：LOOクロスバリデーション) という手法もある</br>\n",
    "LOOでは、kにデータ数と同じ値を設定して、データを1つずつ分割し、そのうちの1データのみを検証データとして扱う</br>\n",
    "\n",
    "- Pros\n",
    "  - データを最大限に利用して検証できることがk-分割交差検証の強み\n",
    "  - データ分割のパターンを変えながら検証を行うので、データ分割の方法に依存しないで精度を確認可能\n",
    "- Cons\n",
    "  - k回の検証を行うので多くの時間が必要\n",
    "\n",
    "\n",
    "![](./images/cross_division.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b44b51-b80d-4682-a42b-21b2c93895e5",
   "metadata": {},
   "source": [
    "## k-分割交差検証の実践\n",
    "scores = model_selection.cross_val_score(svc, X, y, cv=5)\n",
    "### 交差検証法の分割数を「5分割」に指定して出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b86b4530-e4bd-4cf7-a2ad-e6c4cf308a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86666667 0.96666667 0.83333333 0.96666667 0.93333333]\n",
      "Average score : 0.9133333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, datasets, model_selection\n",
    "\n",
    "# 「IRIS」というデータセットを読み込み\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# 機械学習アルゴリズムSVMを使用\n",
    "svc = svm.SVC(C=1, kernel=\"rbf\", gamma=0.001)\n",
    "\n",
    "# 交差検証法を用いてスコアを求める\n",
    "# 内部では、X、yがそれぞれ「X_train, X_test, y_train, y_test」の様に分割され処理\n",
    "scores = model_selection.cross_val_score(svc, X, y, cv=5)\n",
    "\n",
    "# 訓練データと検証データのサイズを確認\n",
    "print (scores)\n",
    "print (\"Average score :\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca1f9fc-9371-4943-864f-55b4086581d3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 過学習\n",
    "学習データにモデルが適合されすぎていて、未知データ(テストデータ)に対して正しく答えを出力できなくなる現象</br>\n",
    "正しく学習されているモデル(未知データに対して当てはありの良いモデル)を汎化しているという</br>\n",
    "さらに過学習とは逆に、「データが十分に学習できていない状態」を学習不足と呼ぶ\n",
    "\n",
    "### どのように過学習を防ぐのか?\n",
    "- 正則化\n",
    "  - 線形回帰式で利用可能\n",
    "  - 係数が大きくなりすぎないように自動でチューニングする(係数が大きくなる場合が多い)\n",
    "- ドロップアウト\n",
    "  - ディープラーニングで利用可能\n",
    "  - モデルの一部が抜け落ちた状態で学習することで過学習を軽減させる\n",
    "- 交差検証法\n",
    "  - 全ての手法で利用可能\n",
    "  - テストデータの全通りの選び方を試すことでデータの偏りによる過学習を防ぐ\n",
    "- ...etc\n",
    "\n",
    "### アンサンブル学習\n",
    "複数のモデルに学習させて、全ての予測結果を統合することで、汎化性能を高める手法\n",
    "\n",
    "- バギング\n",
    "  - 同時に複数のモデルに学習させて、予測結果の平均を取ることで汎化能力を向上させる\n",
    "- ブースティング\n",
    "  - 複数のモデルの異なる予測結果を統合することで、汎化性能を向上させる\n",
    "  - 学習結果を次のモデルの学習に反映させるため同時に処理することはできないが精度が高まることが多い\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f0e625-4158-44c1-9992-c838bcd27978",
   "metadata": {},
   "source": [
    "# 性能評価指標\n",
    "データラベルに偏りがある場合は注意が必要</br>\n",
    "- 病気の診断\n",
    "- 迷惑メール検知\n",
    "\n",
    "## 混同行列\n",
    "- 真陽性(TP): 正解   がんと予測し、実際にがんであった患者の数\n",
    "- 偽陽性(FP): 不正解 がんではないと予測したが、実際はがんであった患者の数\n",
    "- 偽陰性(FN): 不正解 がんと予測したが、実際はがんではなかった患者の数\n",
    "- 真陰性(TN): 正解   がんではないと予測し、実際にがんではなかった患者の数\n",
    "\n",
    "![](./images/result_metric.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6408036b-fbcc-4ae8-ada3-894eb204245e",
   "metadata": {},
   "source": [
    "## 精度評価指標\n",
    "精度評価指標とは？\n",
    "- 正解率(Accuracy)\n",
    "  - 正解率 = TP+TN / FP+FN+TP+TN\n",
    "  - 全てのケースのうち正解した数/全ての数\n",
    "  - カテゴリに偏りがある場合、正解率という指標を使うと直感とずれる可能性がある\n",
    "- 精度(適合率, Precision)\n",
    "　 - TP / TP+FP\n",
    "  - \"正\"と予測されたデータの中で、実際に\"正\"だったデータの割合\n",
    "  - \"顧客の好みでない商品を提案したくない\"などのケースで高い精度が求められる\n",
    "  - 例: WEBサービスのレコメンドなどで重要視される指標\n",
    "- 再現率(Recall)\n",
    "  - TP / TP+FN\n",
    "  - \"正\"だったデータの中で、実際に\"正\"と予測されたデータの割合\n",
    "  - \"絶対にミスしてはいけない\"などのケースでは、高い再現率が求められる\n",
    "  - 例: 医療健診などで最重視される指標\n",
    "- F値 (F-Value)\n",
    "  - 2*精度*再現率 / 精度+再現率\n",
    "  - 2TP / 2TP+FN+FP\n",
    "  - 精度と再現率の調和平均\n",
    "  - 機械学習モデルの評価の際、正解率と並んで最も使われる指標"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f946eab5-a126-4198-9075-7adde71e8636",
   "metadata": {},
   "source": [
    "## sklearn.metricsモジュールにあるconfusion_matrix関数を利用して、実際に混同行列の各成分の個数をみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55f8da4f-f727-4766-940c-53ef051a7115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 1]\n",
      " [0 3]]\n",
      "正解率: 0.8333333333333334\n",
      "精度: 1.0\n",
      "再現率: 0.6666666666666666\n",
      "F-Value: 0.8\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# データを作成 0=陽性, 1=陰性\n",
    "y_true = [0,0,0,1,1,1]\n",
    "y_pred = [1,0,0,1,1,1]\n",
    "\n",
    "confmat = confusion_matrix(y_true, y_pred)\n",
    "# TP: 2, FN: 1, FP: 0, TN: 3\n",
    "print(confmat)\n",
    "\n",
    "accuracy = (confmat[0][0] + confmat[1][1]) / (sum(confmat[0]) + sum(confmat[1]))\n",
    "precision = confmat[0][0]/(confmat[0][0]+confmat[1][0])\n",
    "recall = confmat[0][0]/(confmat[0][0]+confmat[0][1])\n",
    "f_value = 2*precision*recall/(precision+recall)\n",
    "print(\"正解率: {}\".format(accuracy))\n",
    "print(\"精度: {}\".format(precision))\n",
    "print(\"再現率: {}\".format(recall))\n",
    "print(\"F-Value: {}\".format(f_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2023bd-3b5f-42db-96ec-0a594499bd4b",
   "metadata": {},
   "source": [
    "## scikit-learnに実装されている性能評価指標を利用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e389fb63-7a04-480e-a8f9-11755e6d0c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.750\n",
      "Recall: 1.000\n",
      "F1: 0.857\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "y_true = [0,0,0,1,1,1]\n",
    "y_pred = [1,0,0,1,1,1]\n",
    "\n",
    "print(\"Precision: {:.3f}\".format(precision_score(y_true, y_pred)))\n",
    "print(\"Recall: {:.3f}\".format(recall_score(y_true, y_pred)))\n",
    "print(\"F1: {:.3f}\".format(f1_score(y_true, y_pred)))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f5adda-213a-4c51-a549-73bdcaa775a8",
   "metadata": {},
   "source": [
    "## 再現率と適合率の関係\n",
    "二つの性能評価指標の関係は、トレードオフの関係になる\n",
    "トレードオフの関係というのは、再現率を高くしようとすると適合率が低くなり、適合率を高くしようとすると再現率が低くなることを指す\n",
    "\n",
    "- 適合率/精度(precision) \n",
    "  - 陽性であると予測した内の何%が当たっていたかを示す\n",
    "- 再現率(recall)\n",
    "  - 本当に陽性であるケースの内、何%を陽性と判定できたかを示す\n",
    "\n",
    "![](./images/index_cases.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa47cbb-0d24-4feb-b880-d7c3578ac3fe",
   "metadata": {},
   "source": [
    "## PR曲線\n",
    "横軸を再現率(recall)、縦軸を適合率/精度(precision)として、データをプロットしたグラフ\n",
    "\n",
    "例: </br>\n",
    "癌検診を受けた10人の患者に対し、それぞれについて癌である可能性を算出したうえで、それをもとに患者に陽性か陰性か宣告することを考える</br>\n",
    "適合率/精度(precision)は、癌検診で陽性と宣告された患者数の内、本当に癌である患者の割合であり、再現率(recall)は、本当に癌である患者のうち、癌と宣告された割合</br>\n",
    "ここで問題となってくるのは、患者10人を癌の可能性が高い順に並べたとき、上位何番目の人まで陽性と宣告するか</br>\n",
    "この何番目の人まで陽性と宣告するかによって、再現率(recall)・適合率/精度(precision)はともに変わってくる</br>\n",
    "\n",
    "![](./images/pr_curve.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a11287-dc41-4b1d-9eb0-ba9482371f83",
   "metadata": {},
   "source": [
    "### ブレークイーブンポイント(BEP)\n",
    "PR曲線には適合率/精度(precision)と再現率(recall)が一致する点</br>\n",
    "適合率/精度(precision)も再現率(recall)も高いに越したことはないが、</br>\n",
    "トレードオフの関係のため、どちらかを上げようとするとどちらかが下がってしまう</br>\n",
    "F値 という評価指標に触れましたが、ブレークイーブンポイントも同じような概念\n",
    "\n",
    "- 適合率/精度(precision)が高く、再現率(recall)が低い状態\n",
    "  - 無駄は少ないが，取りこぼしの多い判定になっている状態\n",
    "  - 機会損失が生じている\n",
    "- 適合率/精度(precision)が低く、再現率(recall)が高い状態\n",
    "  - 取りこぼしが少ないが，無駄撃ちが多い判定になっている状態\n",
    "  - アプローチの予算が無駄になる可能性が高い\n",
    "\n",
    "![](./images/pr_curve_breakpoint.png)\n",
    "\n",
    "### PR曲線を用いたモデルの評価\n",
    "PR曲線によるモデルの優劣は以下のようになる</br>\n",
    "つまり、BEPが右上に遷移するほど良いモデルが構築できたと言える</br>\n",
    "BEPが右上に遷移するほど、適合率/精度(precision)と再現率(recall)が同時に高くなる\n",
    "\n",
    "![](./images/pr_curve_good_bad.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92292f0-efb0-48e2-b552-0d0bd6c5a8c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca20166-34b2-4320-b147-f7a851e7c181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334161e6-d1af-4e97-8478-08d97687b850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c558933-5fbd-4666-8109-fc0d5b958fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
