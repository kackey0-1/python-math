{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a50c778d-0bbf-4ec9-b289-fd9d1eff83ab",
   "metadata": {},
   "source": [
    "# 教師あり学習(回帰)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86821ed-fe1b-4e9b-aba6-7fa6ffd16aef",
   "metadata": {},
   "source": [
    "## 線形回帰とは?\n",
    "\n",
    "回帰分析とは、予測したいデータに対し、すでにわかっているデータの関係性を元に推定するアプローチ</br>\n",
    "\n",
    "### サンプル1\n",
    "例えば毎分一定量の水が溜まるタンクがある</br>\n",
    "2分後には8L、4分後には16L溜まる</br>\n",
    "5分後にはどれくらいタンクに水量が溜まっているか</br>\n",
    "\n",
    "V=4t (V:水の量(L)、t:時間(分))\n",
    "\n",
    "- 予測したい数値：5分後に溜まっている水量\n",
    "- すでに分かっているデータ：2分後には8L、4分後には16L溜まる\n",
    "\n",
    "回帰ではすでに分かっているデータの関係性(V = 4 tV=4t)を元に、予測したいデータ（5分後に溜まっている水量）を推定\n",
    "\n",
    "### サンプル2\n",
    "\n",
    "このアンケートでは、利用客が「満足度」・「食べ物のおいしさ」・「接客の良さ」の3つを10点満点で評価する</br>\n",
    "店長は、「満足度」の点数を良くするために、「食べ物のおいしさ」と「接客の良さ」のどちらの改善に力を入れたら良いか悩んでいる。</br>\n",
    "\n",
    "- 多くの客が「食べ物のおいしさ」の点数を高くつけた場合、「接客の良さ」の点数にかかわらず「満足度」の点数を高くつけた\n",
    "- 同様に「食べ物のおいしさ」の点数を低くつけた場合には「満足度」の点数を低くつけた\n",
    "\n",
    "T=0.7P1+0.3P2</br>\n",
    "このモデルのP_1P1 、P_2P2の係数を見ると、「食べ物のおいしさ」の点数P_1P1の方が、「満足度」の点数に与える影響は大きいとわかる<br>\n",
    "\n",
    "「満足度」を上げるために「接客の良さ」よりも「食べ物のおいしさ」の改善に力を入れるべきという判断が可能\n",
    "\n",
    "線形式(O^2,O^4など累乗の形がない）で予測する回帰を線形回帰と呼ぶ\n",
    "\n",
    "## scikit-learnを使って線形回帰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88c32ea6-6ffb-4a8b-9509-66911051af5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28.83885359 36.00783288 15.08324755 25.23090886 18.87864064 23.21398327\n",
      " 17.5931124  14.30508093 23.05438985 20.62008346 24.78514683 18.66833668\n",
      " -6.9788951  21.83575737 19.20898992 26.2868054  20.54379176  5.65713224\n",
      " 40.42358065 17.64146116 27.32258958 30.05056174 11.15013704 24.11530393\n",
      " 17.89145648 15.79348591 22.94743453 14.2586068  22.26731194 19.24709013\n",
      " 22.26897546 25.24344002 25.69165643 17.98759507 16.70286649 17.11631225\n",
      " 31.19643534 20.17835831 23.71828436 24.79196868 13.94575895 32.00389982\n",
      " 42.53869791 17.44523722 27.15354457 17.07482215 13.89272021 26.06440323\n",
      " 20.36888769 29.97813037 21.35346608 34.32287916 15.88498671 26.17757739\n",
      " 39.50970314 22.84123308 18.95049088 32.68913818 25.02057949 12.90539147\n",
      " 22.76052302 30.53884316 31.60797905 15.92162168 20.50670563 16.50798147\n",
      " 20.50202198 26.00723901 30.63860954 11.42877835 20.53765181 27.56249175\n",
      " 10.85162601 15.96871769 23.87570192  5.66369672 21.47818991 41.2820034\n",
      " 18.56559986  9.08857252 20.97848452 13.0630057  20.99054395  9.34050291\n",
      " 23.13686588 31.80106627 19.10245917 25.59186169 29.14490119 20.17571514\n",
      " 25.5962149   5.20301905 20.16835681 15.08546746 12.8601543  20.80904894\n",
      " 24.68556943 -0.77450939 13.33875673 15.62703156 22.21755358 24.58188737\n",
      " 10.77302163 19.50068376 23.23450396 11.77388822 18.36777924 25.4383785\n",
      " 20.89079232 24.08440617  7.3658717  19.16424347 21.93734133 27.41191713\n",
      " 32.50857196 14.86885244 35.05912525 12.86075113 20.83043572 28.42077138\n",
      " 15.65853688 24.67196362  3.28420892 23.79879617 25.73329894 23.04815612\n",
      " 24.73046824]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/k-kakimoto/dev/python-math/.ven/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# scikit-learnのLinearRegressionというモデルをインポートします。詳細は1.2で説明します\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "# scikit-learnに標準で搭載されている、ボストン市の住宅価格のデータセットをインポートします\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "# scikit-learnに搭載されているデータセットを学習用と予測結果照合用に分けるツールをインポートします\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# データの読み込みです\n",
    "data = load_boston()\n",
    "\n",
    "# データを教師用とテスト用に分けます\n",
    "train_X, test_X, train_y, test_y = train_test_split(\n",
    "    data.data, data.target, random_state=42)\n",
    "\n",
    "# 学習器の構築です\n",
    "model = LinearRegression()\n",
    "\n",
    "# 以下にコードを追加して、教師データを用いて学習器に学習\n",
    "model.fit(train_X, train_y)\n",
    "# 以下にコードを追加して、テスト用データを用いて学習結果をpred_yに格納\n",
    "pred_y = model.predict(test_X)\n",
    "\n",
    "# 予測結果を出力\n",
    "print(pred_y)\n",
    "# print(\"正解率: %.2f}\"%accuracy_score(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c49a0c2-f433-43ea-a165-f647634c2b2a",
   "metadata": {},
   "source": [
    "## 決定係数R^2\n",
    "決定係数R^2とは、予測データと実際の正解データが、どのくらい一致しているかを示す指標</br>\n",
    "決定係数R^2の定義は、複数あるが、scikit-learnでの定義によると以下の式で表すことができる</br>\n",
    "\n",
    "(決定係数 by scikit-learn)[https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html]\n",
    "\n",
    "![](./images/coefficient_of_determination.png)\n",
    "\n",
    "\n",
    "- 満足度：4点\n",
    "- 食べ物のおいしさ：8点\n",
    "- 接客の良さ：4点\n",
    "\n",
    "エクササイズ 1.2.1では、次のような線形回帰モデルを考えました。\n",
    "\n",
    "T=0.7P1+0.3P2</br>1\n",
    "\n",
    "このモデルに、</br>\n",
    "食べ物のおいしさ：8点、接客の良さ：4点の情報を入力</br>\n",
    "P_1P1に8を、P_2P2に4を代入</br>\n",
    "予測された総合評価TTは、6.8点</br>\n",
    "予測値と正解データとの差が比較的大きいため、このようなアンケートが多く存在すれば、<b>決定係数の値は小さくなり</b>、予測の精度が悪いと判断できる</br>\n",
    "逆に予測値と正解データとの差が小さいアンケートが多ければ、<b>決定係数の値は大きくなり</b>、作成したモデルが精度よく予測できていると判断できる</br>\n",
    "note: 決定係数は0から1の範囲内の値を取る"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e636873a-e8bf-4f24-a2ee-f7e3301acf4a",
   "metadata": {},
   "source": [
    "## 線形単回帰\n",
    "線形単回帰とは、1つの予測したいデータ(例：水の量)を1つのデータ(例：時間)から求める回帰分析</br>\n",
    "主にデータの関係性を調べるときに用いられる\n",
    "\n",
    "- y=ax+b\n",
    "  - 最小二乗法が最も一般的\n",
    "    - 実際のyyの値と推定するy(=ax+b)y(=ax+b)の値の差の二乗の総和が最小になるようにaaとbbを定める方法\n",
    "    - 二乗することによって、正負の相違による誤差の相殺を防ぐ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e49979-e9bd-4b31-8eaf-90495b189863",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# データ生成\n",
    "X, y = make_regression(n_samples=100, n_features=1, n_targets=1, noise=5.0, random_state=42)\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=42)\n",
    "# モデル学習\n",
    "model = LinearRegression()\n",
    "model.fit(train_X, train_y)\n",
    "# test_X, test_yに対する決定係数を出力\n",
    "print(model.score(test_X, test_y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b08299-d94a-4812-bcae-f1914e63ceb3",
   "metadata": {},
   "source": [
    "## 線形重回帰\n",
    "線形重回帰とは、予測したいデータが1つ(例：レストランの満足度の点数)に対し、</br>\n",
    "予測に用いるデータが複数個(例：食べ物のおいしさの点数と接客の良さの点数)ある回帰分析\n",
    "\n",
    "![](./images/multiple_regression.png)\n",
    "\n",
    "線形重回帰もscikit-learnのlinear_modelモジュール内にあるLinearRegressionというモデルを使って回帰分析が可能\n",
    "すでにある学習データに対して1番誤差が少なくなるようにbeta_0,beta_1,beta_2...,epsilonβ が決定されて予測がされる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "019091a4-fc8b-4fd5-afd9-0d5b5c175af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 121.38490116    7.85980009 -124.58963175   41.00261279  -26.63686974\n",
      "   86.54245026 -115.70042851  -86.83134041 -122.47457672 -219.98565432\n",
      "  -94.60953715  -93.78798768   28.52602374  -84.49397404   -6.20979544\n",
      "   21.37516735  -45.33206679  -22.65413603    3.67511216  -29.64743901\n",
      "  -14.68097993   37.34464017    8.28887999   73.27989407  -31.83281179]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# データの生成\n",
    "X, y = make_regression(n_samples=100, n_features=10, n_informative=3, n_targets=1, noise=5.0, random_state=42)\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "# test_Xに対する推測結果を出力\n",
    "# model.score(test_X, test_y)\n",
    "print(model.predict(test_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb04bc60-cf4f-4671-878e-861cc3e21ed5",
   "metadata": {},
   "source": [
    "# モデルの汎化\n",
    "## 汎化\n",
    "過学習を防ぐために取られるアプローチが汎化</br>\n",
    "汎化を意識したモデルを作ることで、学習に使ったデータに適合しすぎず、一般的なケースに対応できるようになる</br>\n",
    "\n",
    "![](./images/generalization.png)</br>\n",
    "過学習をすると学習データ(〇)に過度に適合するので未知のデータの予測がうまくいかない。</br>\n",
    "そこで汎化を施し、未知のデータに適合するようパラメータを調整する。</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512516bf-245c-4e04-9c50-5732ebb8fe3e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 正則化\n",
    "線形回帰では、 汎化手法として正則化が用いられる</br>\n",
    "正則化とは、回帰分析を行うモデルに対し、</br>\n",
    "モデルが推定したデータ同士の関係性の複雑さに対してペナルティを加え、</br>\n",
    "モデルが推定するデータ同士の関係性を一般化しようとするアプローチ</br>\n",
    "\n",
    "## L1正則化\n",
    "- 「予測に影響を及ぼしにくいデータ」にかかる係数をゼロに近づける手法\n",
    "- 主に余分な情報がたくさん存在するようなデータの回帰分析を行う際に用いる \n",
    "- 特徴量削減の手法として用いることもできる\n",
    "\n",
    "## L2正則化\n",
    "- 係数が大きくなりすぎないように制限する手法\n",
    "- 過学習を抑えるために用いられる\n",
    "- 学習の結果、得られる係数が大きくならないので汎化しやすいという特徴"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e671238-d13f-49fb-a148-b97aa2644139",
   "metadata": {},
   "source": [
    "## ラッソ回帰\n",
    "L1正則化を行いながら線形回帰の適切なパラメータを設定する回帰モデル</br>\n",
    "\n",
    "L1正則化では、データとして余分な情報がたくさん存在するようなデータの回帰分析を行う際に使用するため、</br>\n",
    "データセットの数（行数）に比べて、パラメータの数（列数）が多い場合には、ラッソ回帰を利用するのが良い"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d11924b-c12d-4f44-9775-5c6b7df5599a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression:0.8478209051074991\n",
      "Lasso regression:0.967921092593941\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# データを生成\n",
    "X, y = make_regression(n_samples=100, n_features=100, n_informative=60, n_targets=1, random_state=42)\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=42)\n",
    "# 線形回帰\n",
    "linear = LinearRegression()\n",
    "linear.fit(train_X, train_y)\n",
    "# test_X, test_yに対する決定係数を出力\n",
    "print(\"Linear regression:{}\".format(linear.score(test_X, test_y)))\n",
    "# ラッソ回帰\n",
    "lasso = Lasso()\n",
    "lasso.fit(train_X, train_y)\n",
    "# test_X, test_yに対する決定係数を出力\n",
    "print(\"Lasso regression:{}\".format(lasso.score(test_X, test_y)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ed5330-53c2-4ded-b77b-66d01d94f94c",
   "metadata": {},
   "source": [
    "## リッジ回帰\n",
    "L2正則化を行いながら線形回帰の適切なパラメータを設定する回帰モデル</br>\n",
    "\n",
    "リッジ回帰には、汎化しやすいという特徴がある</br>\n",
    "scikit-learnのlinear_modelモジュール内にあるRidge()というモデルがリッジ回帰のモデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57e55b66-75dd-4e21-be54-9d9be023ee5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression:0.7802322835148339\n",
      "Ridge regression:0.7807547182116578\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# データを生成\n",
    "X, y = make_regression(n_samples=100, n_features=50, n_informative=50, n_targets=1, noise=100.0, random_state=42)\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# 線形回帰\n",
    "linear = LinearRegression()\n",
    "linear.fit(train_X, train_y)\n",
    "# test_X, test_yに対する決定係数を出力\n",
    "print(\"Linear regression:{}\".format(linear.score(test_X, test_y)))\n",
    "# リッジ回帰\n",
    "ridge = Ridge()\n",
    "ridge.fit(train_X, train_y)\n",
    "# test_X, test_yに対する決定係数を出力\n",
    "print(\"Ridge regression:{}\".format(ridge.score(test_X, test_y)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c83dc3c-4093-412c-bf24-527cbc1717a2",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda409f6-326a-4a9d-89ac-0a232cac2cd5",
   "metadata": {},
   "source": [
    "## ElasticNet回帰\n",
    "ラッソ回帰とリッジ回帰を組み合わせて正則化項を作るモデル\n",
    "\n",
    "- Pros\n",
    "  - ラッソ回帰で取り扱った余分な情報がたくさん存在するようなデータに対して情報を取捨選択してくれる点\n",
    "  - リッジ回帰で取り扱った 汎化しやすい点\n",
    "\n",
    "訓練データにラッソ回帰、リッジ回帰、ElasticNet回帰を適用して精度を検証し、最も精度が良い回帰モデルを採用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "830cc1dc-eece-48a8-82af-2aaecb1fcc72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression:0.8478209051074991\n",
      "Lasso regression:0.967921092593941\n",
      "Ridge regression:0.8345609657678084\n",
      "Ridge regression:0.6094881004267583\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# データを生成\n",
    "# X, y = make_regression(n_samples=100, n_features=50, n_informative=50, n_targets=1, noise=100.0, random_state=42)\n",
    "# train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=42)\n",
    "X, y = make_regression(n_samples=100, n_features=100, n_informative=60, n_targets=1, random_state=42)\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# 線形回帰\n",
    "linear = LinearRegression()\n",
    "linear.fit(train_X, train_y)\n",
    "# test_X, test_yに対する決定係数を出力\n",
    "print(\"Linear regression:{}\".format(linear.score(test_X, test_y)))\n",
    "# ラッソ回帰\n",
    "lasso = Lasso()\n",
    "lasso.fit(train_X, train_y)\n",
    "# test_X, test_yに対する決定係数を出力\n",
    "print(\"Lasso regression:{}\".format(lasso.score(test_X, test_y)))\n",
    "# リッジ回帰\n",
    "ridge = Ridge()\n",
    "ridge.fit(train_X, train_y)\n",
    "# test_X, test_yに対する決定係数を出力\n",
    "print(\"Ridge regression:{}\".format(ridge.score(test_X, test_y)))\n",
    "# ElasticNet回帰\n",
    "# l1_ratioを設定すると、L1正則化とL2正則化の割合を指定可能\n",
    "# l1_ratio=0.3の場合、L1正則化が30％、L2正則化が70％効いている\n",
    "elasticnet = ElasticNet(l1_ratio=0.3)\n",
    "elasticnet.fit(train_X, train_y)\n",
    "print(\"Ridge regression:{}\".format(elasticnet.score(test_X, test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4221c37-f180-4c42-b1b0-142fbf350b34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c243ee-90c7-4e88-80d4-e70ade79a0f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16efffd4-5a93-42cf-8307-d8472db6f461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5ee87c-dc09-4dd7-a65f-3ddd007ea7d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c027620-048b-4789-9f69-cd98235c1e39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
